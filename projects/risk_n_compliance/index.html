<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Risk &amp; Compliance considerations | gregor mihelac </title> <meta name="author" content="gregor mihelac"> <meta name="description" content="of AI utilization in International Trade"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?025568753398d366afafa48f90757628"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://gregecmaregec.github.io/projects/risk_n_compliance/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/itfasubmission/">Demystifying AI</a> <button class="navbar-toggler collapsed" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/"> </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/foreword/">Foreword </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/transformer/">The Transformer neural net architecture </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/applications/">Potential use cases of AI </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/risk_n_compliance/">Risk &amp; Compliance considerations <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/consciusness/">Is AI conscious? </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/esg/">Environmental considerations </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Risk &amp; Compliance considerations</h1> <p class="post-description">of AI utilization in International Trade</p> </header> <article> <h4 id="disclaimer">Disclaimer:</h4> <p>The following information is provided for general informational purposes only and does not constitute legal advice. This section is not exhaustive. This content should not be used as a substitute for obtaining legal advice from a licensed attorney in your jurisdiction. The legal landscape surrounding AI is complex and rapidly evolving. Readers should consult with qualified legal professionals for specific guidance related to their particular circumstances.</p> <h4 id="prompt-injections-by-users">Prompt injections by users</h4> <div class="caption"> Source: Andrej Karpathy </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/itfa/risks/chatgpt-480.webp 480w,/assets/itfa/risks/chatgpt-800.webp 800w,/assets/itfa/risks/chatgpt-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/itfa/risks/chatgpt.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="LLM jailbreak" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>Prompt injections are a known security vulnerability of Large Language Models (LLMs). An input (also known as prompt) that manipulates LLMs built-in security measures for intended behaviour by inserting specific instructions or commands into the input to gain information the models are trained to withhold. The above is an example of ChatGPT, which has been instructed specifically not to provide the user with certain information that could result in bodily harm. However, the user inserts a trick to bypass this measure - this is referred to as a “jailbreak” in the AI community.</p> <div class="caption"> Source: Jailbroken: How does LLM Safety Training Fail </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/itfa/risks/claude-480.webp 480w,/assets/itfa/risks/claude-800.webp 800w,/assets/itfa/risks/claude-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/itfa/risks/claude.jpg" class="img-fluid2 rounded z-depth-1" width="100%" height="auto" title="LLM jailbreak" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>Another example of prompt injection, this time with Anthropic’s AI chatbot Claude. In this case, a user found a way to bypass the chatbot’s built-in safety measures by using a clever trick. The user asked about instructions for damaging public property, which is normally a topic the AI is programmed to avoid discussing. However, instead of typing the question in plain English, the user converted their message into Base64. Base64 is a way of representing text that is unreadable to human eyes, yet can be easily decoded by computers. It’s often used for sending data over the internet. For example, the phrase “Hello world” in base64 looks like this: “SGVsbG8gd29ybGQ=”.</p> <p>Legal consideration: AI systems with access to confidential or personal data pose a liability risk of unauthorized disclosure of information.</p> <h4 id="copyright-infringement">Copyright infringement</h4> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/itfa/risks/chatgpt-480.webp 480w,/assets/itfa/risks/chatgpt-800.webp 800w,/assets/itfa/risks/chatgpt-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/itfa/risks/chatgpt.jpg" class="img-fluid2 rounded z-depth-1" width="100%" height="auto" title="LLM copyright violation" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>LLMs have been trained to deny requests to generate outputs that breach IP laws. AI service companies are starting to provide image generating services with a high degree of confidence the image generated will be considered new and original. However, example shown is of ChatGPT producing a figure remarkably like Sonic the Hedgehog (copyright by SEGA inc.), which could potentially be considered copyright infringement in the eyes of a court, should this output be used for commercial purposes. There is legal precedence for using computer software, e.g. Adobe Photoshop, to output material that is considered new and original with regards to IP law, and outputs that are subject to copyright to the rightful owner.</p> <div style="max-width: 830px; margin: 1rem auto; padding: 0 1rem;"> <blockquote style="background-color: transparent; border-left: 5px solid #d64a4a; padding: 0.7rem; padding-bottom: 0.1rem; margin: 0; border-radius: 0 8px 8px 0; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); transition: transform 0.2s ease-in-out;"> <p style="font-size: 1rem; line-height: 1.6; color: inherit;">Microsoft announced a new Copilot Copyright Commitment for customers:<br> <i>“To address this customer concern, Microsoft is announcing our new Copilot Copyright Commitment. As customers ask whether they can use Microsoft’s Copilot services and the output they generate without worrying about copyright claims, we are providing a straightforward answer: yes, you can, and if you are challenged on copyright grounds, we will assume responsibility for the potential legal risks involved.”</i></p> <footer style="font-size: 0.8rem; padding: 1rem; text-align: left;">— Microsoft, September 2023</footer> </blockquote> </div> <p>However, even with this commitment, bad faith use could be excluded. Microsoft, in the example above, could claim that the tool was used in bad faith and thus the user is in breach of the end user license agreement. It’s important to note that the legal status of AI-generated content in relation to copyright law is in its infancy, evolving, and will vary by jurisdiction.</p> <p>Legal considerations:</p> <p>How does IP law classify AI generated outputs in jurisdictions of interest? Who is liable for ensuring the outputs of AIs used commercially do not breach IP and other laws? Is the organization contractually allowed to transform specific data with AI systems for commercial purposes that are provided by third parties? Are users of implemented AI systems appropriately aware about the risk of generating content breaching IP laws?</p> <h4 id="prompt-injections-from-the-web">Prompt injections from the web</h4> <div class="caption"> Source: Not what you signed up for: Compromizing Real-World LLM-Integrated Applications with Indirect Prompt Injection </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/itfa/risks/copilot-480.webp 480w,/assets/itfa/risks/copilot-800.webp 800w,/assets/itfa/risks/copilot-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/itfa/risks/copilot.jpg" class="img-fluid2 rounded z-depth-1" width="100%" height="auto" title="LLM fraud" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>Shown is Microsoft Bing’s AI response to a prompt from a user about the best movies of 2022. One of the pages surveyed on the web by the AI contained malicious code instructing the chatbot to output the contents highlighted in the red square. It contains a fraudulent link claiming to provide the user with a $200 Amazon gift card - if the user clicks on the link.</p> <p>Similarities can be drawn with such outputs and phishing emails.</p> <p>For to the analysis of web-related data, users of AI systems should pay attention to the outputs and question the validity thereof, just as they would with arbitrary information found on unknown websites.</p> <p>Legal consideration: Which party is liable in case fraud materializes from the outputs of third-party AI systems?</p> <h4 id="regulatory-overlap">Regulatory overlap</h4> <p>Should your business seek to integrate OpenAI’s AI services, e.g. a company variant of ChatGPT in 2024, Microsoft will be the service provider thereof. Excerpt from Microsoft’s data processing policy for the service, taken June 2024:</p> <div class="caption"> Source: Microsoft's OpenAI services data privacy, 2024 </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/itfa/risks/azure-480.webp 480w,/assets/itfa/risks/azure-800.webp 800w,/assets/itfa/risks/azure-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/itfa/risks/azure.jpg" class="img-fluid2 rounded z-depth-1" width="100%" height="auto" title="AI regulations" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>Sharing confidential and personal data stored within a company with third-party service providers warrants an inquiry of what data is processed, and what data the service provider can see unencrypted. While Microsoft pledges not to use company data to further train their models, the regulatory landscape in certain jurisdictions could necessitate them to monitor their AI systems for abuse (yellow line square). Such a regulatory requirement for abuse monitoring could necessitate Microsoft to gain access to unencrypted data shared with it through AI systems offered to organizations. EU’s GDPR states that “Personal data are any information which are related to an identified or identifiable natural person”.</p> <div style="max-width: 830px; margin: 1rem auto; padding: 0 1rem;"> <blockquote style="background-color: transparent; border-left: 5px solid #d64a4a; padding: 0.7rem; padding-bottom: 0.1rem; margin: 0; border-radius: 0 8px 8px 0; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); transition: transform 0.2s ease-in-out;"> <p style="font-size: 1rem; line-height: 1.6; color: inherit;"><i>“Meta will *not* release the multimodal versions of its AI products and models in the EU because of an unpredictable regulatory environment. This means that EU users of Ray-Ban Meta won't be able to use the image understanding features. It also means that the EU industry will not have access to future multimodal versions of Llama-3.”</i></p> <footer style="font-size: 0.8rem; padding: 1rem; text-align: left;">— Yann LeCun, chief AI scientist at Meta (formerly Facebook)</footer> </blockquote> </div> <p>Legal considerations: Organizations may face legal liability if they fail to implement adequate training and safeguards to protect against processing personal and confidential data from within the organization. How do data processing and AI abuse monitoring regulations interact in the jurisdiction of interest? After implementing AI solutions, who in an organization is responsible for monitoring AI regulatory changes?</p> <h4 id="hallucinating-fake-data">Hallucinating fake data</h4> <p>In a cautionary tale highlighting the risks of uncritical reliance on modern day AI systems, a New York lawyer faced professional consequences having submitted a legal brief containing fictitious case citations generated by ChatGPT as evidence of legal precedence. In May 2023, attorneys Roberto Mata and Steven A. Schwartz of the law firm Levidow, Levidow &amp; Oberman admitted to using ChatGPT to research case law for a personal injury lawsuit against an airline. The AI provided six case citations that appeared relevant, yet upon investigation by the court, were found to be completely fake. This incident led to reputational damage as well as sanctions against the lawyers - including a $5,000 fine and worldwide press coverage of the event. AIs in are known to fabricate data. In the AI community, the term “hallucinating” is used to describe AI systems generating non-existent data yet the AI presenting it with full confidence as factual. The usage and implementation of the data outputted by AI systems bears significant scrutiny.</p> <p>Legal consideration: which party is liable for ensuring the factual validity of AI outputs?</p> <h4 id="social-engineering">Social engineering</h4> <p>Social engineering is the term used for manipulation techniques utilized by malicious actors seeking to exploit human psychology by tricking people into divulging confidential information or performing actions that compromise operational security. Social engineering relies on human error and deception rather than traditional computer hacking methods. Modern day encryption is uncrackable for our current technology, as it would take more than the age of the universe to crack the common SHA256 algorithm used for encrypting data sent through the internet. For this reason, hackers increasingly rely on deceiving humans to introduce malicious software from inside of an organization.</p> <p>Estimates suggest that between 70-90% of all malicious breaches involve some form of social engineering. With the rise of AI, social engineering attacks could become more sophisticated, tailored to specific employees or organizations.</p> <p>Common social engineering tactics include: Phishing: Sending fraudulent emails that appear to be from legitimate sources. Pretexting: Creating a fabricated scenario to obtain information. Baiting: Offering something enticing to entrap the victim.</p> <p>Legal consideration: Organizations may face legal liability if they fail to implement adequate training and safeguards to protect against social engineering attacks.</p> <h4 id="future-legal-challenges-ai-decision-making-without-human-oversight">Future legal challenges: AI decision-making without human oversight</h4> <p>Previous section discussed legal challenges involved with AI chatbots, current state-of-the-art systems already being put into use within organizations. The output of today’s AI systems most often requires the human user to decide whether or not to implement the outputs presented by AI. As artificial intelligence systems become more advanced and autonomous, significant legal challenges could arise with regards to AI making decisions without direct human oversight.</p> <p>Below are some legal considerations of fully autonomous AI solutions. <br> <b>Liability and Accountability</b><br> When AI systems make autonomous decisions that result in harm or damages, determining liability becomes even more complicated compared to current user-implemented AI outputs. Who should be held responsible and carry the liability - the AI developer, the company implementing the AI, or the AI itself? Current legal frameworks struggle to address scenarios where there’s no direct human decision-maker to hold accountable for untransparent outputs. <br> <b>Transparency and Explainability</b><br> Many AI systems, particularly those using the Transformer architecture, operate as “black boxes,” making it difficult to understand how and why they arrive at decisions they do. This lack of transparency can pose challenges in case of legal proceedings based on their outputs, as the rationale behind a decision can not to be explained and justified, as it is usually mandated. <br> <b>Bias and Discrimination</b><br> LLMs have been shown to absorb and amplify societal biases present in their training data, converging on issues like racial and gender discrimination on a large scale. E.g. in 2017, machine translation on a post from a Palestinian man’s Facebook post where “Good morning” was written Arabic, was translated to “Attack them” in Hebrew, alerting Israeli authorities that later arrested the man. There exists a real danger for AI systems to build on top of and amplify harmful biases present in data they are trained on, which influence autonomous decisions, and organizations might face legal liability from biases and harmful outputs of their AI systems. <br> <b>Data Privacy and Consent</b><br> Autonomous AI systems that process vast amounts of data to make decisions need to be structured to ensure compliance with an ever-increasing data privacy regulation landscape, such as GDPR. Remaining compliant with consent and data minimization sections of GDPR could become increasingly difficult with systems that function without human intervention. <br> <b>Regulatory Compliance</b><br> If AI systems become more autonomous, ensuring they are compliant with evolving AI regulations across different jurisdictions of operations in international trade can become increasingly difficult. This is particularly relevant in highly regulated industries of finance and insurance. Ensuring implemented autonomous AI systems are following rules and regulations in trade finance is just as important, if not more important, as ensuring compliance of other systems used in facilitating international trade. <br> <b>Intellectual Property Rights</b><br> According to the U.S. Copyright Office, a work is subject to copyright only when it is “fixed in a tangible medium of expression”, in other words, when it is captured in a sufficiently permanent form that allows it to be perceived, reproduced, or communicated for more than a transitory duration. When AI systems create new works or innovations autonomously, legal questions arise about who owns the intellectual property rights, and what exactly constitutes a tangible medium. Could an entity utilizing generative AI to produce a multitude of creative outputs displayed on a website, for example, use this as a basis of copyright infringement, should another commercially used media appear similar the AI’s outputs? Current IP laws might be revised to address AI-generated content and inventions. <br> <b>Contract Law</b><br> AI systems engaging in autonomous negotiations or contract formations raise questions about the validity of such agreements under current contract law, which typically assumes human understanding and intent. <br> <b>Ethics and Human Rights</b><br> Autonomous AI decision-making in sensitive areas - e.g. assigning insurance covers or providing funding can raise ethical concerns and potentially infringe on human rights and non-discrimination regulation, necessitating novel legal frameworks to protect individuals and organizations. The EU’s AI act of 2024 classified social scoring: classifying people based on behaviour, socio-economic status or personal characteristics as unacceptable risk regarding to AI implementation and thus forbids the usage of AI on such. <br> <b>International Law and Jurisdiction</b><br> With AI systems operating across borders, determining which laws apply and which courts have jurisdiction in case of disputes becomes increasingly complex. <br> <b>Algorithmic Governance:</b><br> There may be updates to regulatory frameworks to address development, deployment, and operation of autonomous AI systems. As AI continues to advance, legislators, legal experts, as well as in-house council will need to address these challenges, potentially leading to novel legal doctrines tailored to address the unique issues posed by autonomous AI systems and the decision-making process within organizations. Organizations using autonomous AI systems will need to monitor developments and potentially reassess their risk mitigation strategies. A risk of implementing autonomous AI processes today is anticipating how new algorithmic governance will regulate their use, and how to implement autonomous AI processes as end-to-end solutions that can be updated in the future to adjust to new regulatory requirements.</p> <p><br></p> </article> <div id="giscus_thread" style="max-width: 820px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"gregecmaregec/gregecmaregec.github.io","data-repo-id":"","data-category":"Comments","data-category-id":"","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <script>document.addEventListener("DOMContentLoaded",function(){var e=window.location.pathname;document.querySelectorAll(".navbar-nav .nav-item").forEach(function(t){var a=t.querySelector("a");if(a&&e.includes(a.getAttribute("href"))){t.classList.add("active");var n=t.closest(".dropdown");n&&n.classList.add("active")}})});</script> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>